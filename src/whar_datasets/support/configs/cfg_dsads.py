from whar_datasets.core.config import (
    Common,
    Dataset,
    GivenSplit,
    Parsing,
    WHARConfig,
    Info,
    Preprocessing,
    Selections,
    SlidingWindow,
    Split,
    SubjCrossValSplit,
    Training,
)

import os
from typing import Dict, Tuple
import pandas as pd
from tqdm import tqdm

SENSOR_COLS = [
    # Trunk (T)
    "T_xacc",
    "T_yacc",
    "T_zacc",
    "T_xgyro",
    "T_ygyro",
    "T_zgyro",
    "T_xmag",
    "T_ymag",
    "T_zmag",
    # Right Arm (RA)
    "RA_xacc",
    "RA_yacc",
    "RA_zacc",
    "RA_xgyro",
    "RA_ygyro",
    "RA_zgyro",
    "RA_xmag",
    "RA_ymag",
    "RA_zmag",
    # Left Arm (LA)
    "LA_xacc",
    "LA_yacc",
    "LA_zacc",
    "LA_xgyro",
    "LA_ygyro",
    "LA_zgyro",
    "LA_xmag",
    "LA_ymag",
    "LA_zmag",
    # Right Leg (RL)
    "RL_xacc",
    "RL_yacc",
    "RL_zacc",
    "RL_xgyro",
    "RL_ygyro",
    "RL_zgyro",
    "RL_xmag",
    "RL_ymag",
    "RL_zmag",
    # Left Leg (LL)
    "LL_xacc",
    "LL_yacc",
    "LL_zacc",
    "LL_xgyro",
    "LL_ygyro",
    "LL_zgyro",
    "LL_xmag",
    "LL_ymag",
    "LL_zmag",
]

ACTIVITY_MAP = {
    1: "sitting",
    2: "standing",
    3: "lying on back",
    4: "lying on right side",
    5: "ascending stairs",
    6: "descending stairs",
    7: "standing in an elevator still",
    8: "moving around in an elevator",
    9: "walking in a parking lot",
    10: "walking on treadmill (flat, 4 km/h)",
    11: "walking on treadmill (15° incline, 4 km/h)",
    12: "running on treadmill (8 km/h)",
    13: "exercising on a stepper",
    14: "exercising on a cross trainer",
    15: "cycling on exercise bike (horizontal)",
    16: "cycling on exercise bike (vertical)",
    17: "rowing",
    18: "jumping",
    19: "playing basketball",
}


def parse_dsads(
    dir: str, activity_id_col: str
) -> Tuple[pd.DataFrame, pd.DataFrame, Dict[int, pd.DataFrame]]:
    dir = os.path.join(dir, "data/")

    sub_dfs = []

    for activity_dir in os.listdir(dir):
        # get activity from dirname
        activity_id = int(activity_dir[1:])

        activity_dir = os.path.join(dir, activity_dir)

        for subject_dir in os.listdir(activity_dir):
            # get subject id from dirname
            subject_id = int(subject_dir[1:])

            subject_dir = os.path.join(activity_dir, subject_dir)

            sub_df = pd.concat(
                [
                    pd.read_csv(
                        os.path.join(subject_dir, file),
                        header=None,
                        names=SENSOR_COLS,
                    )
                    for file in [
                        f for f in os.listdir(subject_dir) if f.endswith(".txt")
                    ]
                ]
            )

            # fill nans in sensor cols with linear interpolation
            sub_df.loc[:, SENSOR_COLS] = sub_df[SENSOR_COLS].interpolate(
                method="linear"
            )

            sub_df["subject_id"] = subject_id
            sub_df["activity_id"] = activity_id

            sub_dfs.append(sub_df)

    # concat all sub_dfs
    df = pd.concat(sub_dfs)

    # identify where activity or subject changes or chnage in nan entries
    changes = (df["activity_id"] != df["activity_id"].shift(1)) | (
        df["subject_id"] != df["subject_id"].shift(1)
    )

    # assign a unique session to each continuous segment
    df["session_id"] = changes.cumsum()

    # add timestamp column per session
    sampling_interval = 1 / 25 * 1e9  # 25 Hz → 0.02 seconds -> to ns
    df["timestamp"] = (
        df.groupby("session_id", group_keys=False).cumcount() * sampling_interval
    )
    df["timestamp"] = pd.to_datetime(df["timestamp"], unit="ns")

    # add activity name
    df["activity_name"] = df["activity_id"].map(ACTIVITY_MAP)

    # factorize
    df["activity_id"] = df["activity_id"].factorize()[0]
    df["subject_id"] = df["subject_id"].factorize()[0]
    df["session_id"] = df["session_id"].factorize()[0]

    # create activity index
    activity_metadata = (
        df[["activity_id", "activity_name"]]
        .drop_duplicates(subset=["activity_id"], keep="first")
        .reset_index(drop=True)
    )

    # create session_metadata
    session_metadata = (
        df[["session_id", "subject_id", "activity_id"]]
        .drop_duplicates(subset=["session_id"], keep="first")
        .reset_index(drop=True)
    )

    # create sessions
    sessions: Dict[int, pd.DataFrame] = {}

    # loop over sessions
    loop = tqdm(session_metadata["session_id"].unique())
    loop.set_description("Creating sessions")

    for session_id in loop:
        # get session df
        session_df = df[df["session_id"] == session_id]

        # drop nan rows
        session_df = session_df.dropna()

        # drop metadata cols
        session_df = session_df.drop(
            columns=[
                "session_id",
                "subject_id",
                "activity_id",
                "activity_name",
            ]
        ).reset_index(drop=True)

        # set types
        session_df["timestamp"] = pd.to_datetime(session_df["timestamp"], unit="ms")
        dtypes = {col: "float32" for col in session_df.columns if col != "timestamp"}
        dtypes["timestamp"] = "datetime64[ms]"
        session_df = session_df.round(6)
        session_df = session_df.astype(dtypes)

        # add to sessions
        sessions[session_id] = session_df

    # set metadata types
    activity_metadata = activity_metadata.astype(
        {"activity_id": "int32", "activity_name": "string"}
    )
    session_metadata = session_metadata.astype(
        {"session_id": "int32", "subject_id": "int32", "activity_id": "int32"}
    )

    return activity_metadata, session_metadata, sessions


cfg_dsads = WHARConfig(
    common=Common(
        datasets_dir="./datasets",
    ),
    dataset=Dataset(
        info=Info(
            id="dsads",
            download_url="https://archive.ics.uci.edu/static/public/256/daily+and+sports+activities.zip",
            sampling_freq=25,
            num_of_subjects=8,
            num_of_activities=19,
            num_of_channels=45,
        ),
        parsing=Parsing(parse=parse_dsads),
        preprocessing=Preprocessing(
            selections=Selections(
                activity_names=[
                    "sitting",  # A1
                    "standing",  # A2
                    "lying on back",  # A3
                    "lying on right side",  # A4
                    "ascending stairs",  # A5
                    "descending stairs",  # A6
                    "standing in an elevator still",  # A7
                    "moving around in an elevator",  # A8
                    "walking in a parking lot",  # A9
                    "walking on treadmill (flat, 4 km/h)",  # A10
                    "walking on treadmill (15° incline, 4 km/h)",  # A11
                    "running on treadmill (8 km/h)",  # A12
                    "exercising on a stepper",  # A13
                    "exercising on a cross trainer",  # A14
                    "cycling on exercise bike (horizontal)",  # A15
                    "cycling on exercise bike (vertical)",  # A16
                    "rowing",  # A17
                    "jumping",  # A18
                    "playing basketball",  # A19
                ],
                sensor_channels=[
                    # Trunk (T)
                    "T_xacc",
                    "T_yacc",
                    "T_zacc",
                    "T_xgyro",
                    "T_ygyro",
                    "T_zgyro",
                    "T_xmag",
                    "T_ymag",
                    "T_zmag",
                    # Right Arm (RA)
                    "RA_xacc",
                    "RA_yacc",
                    "RA_zacc",
                    "RA_xgyro",
                    "RA_ygyro",
                    "RA_zgyro",
                    "RA_xmag",
                    "RA_ymag",
                    "RA_zmag",
                    # Left Arm (LA)
                    "LA_xacc",
                    "LA_yacc",
                    "LA_zacc",
                    "LA_xgyro",
                    "LA_ygyro",
                    "LA_zgyro",
                    "LA_xmag",
                    "LA_ymag",
                    "LA_zmag",
                    # Right Leg (RL)
                    "RL_xacc",
                    "RL_yacc",
                    "RL_zacc",
                    "RL_xgyro",
                    "RL_ygyro",
                    "RL_zgyro",
                    "RL_xmag",
                    "RL_ymag",
                    "RL_zmag",
                    # Left Leg (LL)
                    "LL_xacc",
                    "LL_yacc",
                    "LL_zacc",
                    "LL_xgyro",
                    "LL_ygyro",
                    "LL_zgyro",
                    "LL_xmag",
                    "LL_ymag",
                    "LL_zmag",
                ],
            ),
            sliding_window=SlidingWindow(window_time=2.56, overlap=0),
        ),
        training=Training(
            split=Split(
                given_split=GivenSplit(
                    train_subj_ids=list(range(0, 7)),
                    test_subj_ids=list(range(7, 8)),
                ),
                subj_cross_val_split=SubjCrossValSplit(
                    subj_id_groups=[[0, 1], [2, 3], [4, 5], [6, 7]],
                ),
            ),
        ),
    ),
)
